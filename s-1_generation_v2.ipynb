{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hkrep\\anaconda3\\envs\\et\\lib\\site-packages\\tqdm\\std.py:668: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import torch\n",
    "import logging\n",
    "import utils.data_loader as data_loader\n",
    "import utils.display as display\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from scipy.spatial.distance import cdist\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics.pairwise import haversine_distances\n",
    "import charging_behavior.where_to_charge.NN_utility_model as NN_utility_model\n",
    "\n",
    "display.configure_pandas()\n",
    "display.configure_logging()\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22-Jul-20 16:52:35 - Loadingdata/cs/ChargeLocation201407\n"
     ]
    }
   ],
   "source": [
    "# Charging station data\n",
    "df_cs, dates = data_loader.load_cs(date=datetime(2014, 7, 1))\n",
    "df_cs = df_cs.loc[~df_cs['cs_name'].isin(['LJDL', 'E04', 'BN0002', 'F11',\n",
    "                                          'S1', 'S2', 'F12', 'F13', 'F15'])].reset_index()\n",
    "cs_location = df_cs[['Latitude', 'Longitude']].to_numpy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22-Jul-20 16:52:35 - Loadingdata/rest/generated_rest_event_v1.csv\n",
      "22-Jul-20 16:52:35 - Loadingdata/rest/rest_events.csv\n",
      "22-Jul-20 16:52:35 - Loadingdata/od/od_with_distance_between_before.csv\n",
      "22-Jul-20 16:52:36 - Loading data/od/full_od_with_hotpots_v4.csv\n",
      "22-Jul-20 16:52:37 - Load data/transit_matrix/full_load_clusters.list_of_dict_v4\n",
      "22-Jul-20 16:52:37 - Load data/transit_matrix/full_drop_clusters.list_of_dict_v4\n",
      "22-Jul-20 16:52:37 - Loading data/ce/v5_30min.csv\n"
     ]
    }
   ],
   "source": [
    "# Rest events and generated rest events\n",
    "generated_rest = data_loader.load_generated()\n",
    "rest_events = data_loader.load_rest()\n",
    "\n",
    "# OD data\n",
    "od_distance = data_loader.load_od(scale='full', with_distance=True)\n",
    "od_with_hs = data_loader.load_od(with_hotpots=True, version='v4')\n",
    "od_with_hs = od_with_hs[['Licence', 'begin_time', 'end_time', 'in_bbox', 'load_label', 'drop_label']]\n",
    "od_with_hs = od_with_hs.merge(od_distance[['Licence', 'begin_time', 'distance_before_od', 'od_distance']])\n",
    "\n",
    "# Pick-up hotspots and  drop-off hotspots\n",
    "p_hs = data_loader.load_clusters()\n",
    "d_hs = data_loader.drop_clusters()\n",
    "p_hs = pd.DataFrame.from_dict(p_hs)\n",
    "d_hs = pd.DataFrame.from_dict(d_hs)\n",
    "\n",
    "with open('generated_data/generation_input/departure_distributions.pickle', mode='rb') as f:\n",
    "    departure_distributions = pickle.load(f)\n",
    "\n",
    "# Transit matrices\n",
    "with open('data/transit_matrix/p2d_v3.list_of_df', 'rb') as f:\n",
    "    p2d = pickle.load(f)\n",
    "with open('data/transit_matrix/p2d_time_v3.list_of_df', 'rb') as f:\n",
    "    p2d_t = pickle.load(f)\n",
    "with open('data/transit_matrix/d2p_v3.list_of_df', 'rb') as f:\n",
    "    d2p = pickle.load(f)\n",
    "with open('data/transit_matrix/d2p_time_v3.list_of_df', 'rb') as f:\n",
    "    d2p_t = pickle.load(f)\n",
    "p2d_distance = pd.read_csv('generated_data/generation_input/p2d_distance.csv', index_col=[0, 1])['od_distance']\n",
    "d2p_distance = pd.read_csv('generated_data/generation_input/d2p_distance.csv', index_col=[0, 1])['distance_before_od']\n",
    "\n",
    "# Charging events\n",
    "ce = data_loader.load_ce(version='v5_30min')\n",
    "common = data_loader.load_trajectory_od_intersection()\n",
    "ce = ce.loc[ce['licence'].isin(common)].reset_index(drop=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22-Jul-20 16:52:37 - Loading charging_behavior/whether_to_charge/model_80train.pickle\n",
      "22-Jul-20 16:52:37 - Loading charging_behavior/whether_to_charge/StandardScaler.pickle\n"
     ]
    }
   ],
   "source": [
    "# predictions = wtc_model.predict(test_X) ['hour', 'weekday', 'min_dis', 'max_dis', 'avg_dis', 'mid_dis']\n",
    "wtc_model, whether_charge_scaler = data_loader.pickle_load('if_to_charge')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22-Jul-20 16:52:37 - cuda is available\n"
     ]
    }
   ],
   "source": [
    "# Choose a device to deploy NN\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "logging.info(device + ' is available')\n",
    "# 初始化模型并加载参数\n",
    "model = NN_utility_model.Net()\n",
    "model.to(device)\n",
    "# model_path = r'C:\\Users\\hkrep\\PycharmProjects\\ChargingEventsExtraction\\data\\preference_learning\\pytorch_model\\para_v2'\n",
    "model_path = 'charging_behavior/where_to_charge/para_v3_30epoch.pkl'\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.eval()\n",
    "softmax = torch.nn.Softmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3755311fd801417f87180c14dce4ba19"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def generation(vehicle_rest):\n",
    "#     if vehicle_rest.name > 3:\n",
    "#         return\n",
    "    \n",
    "    # Initializaiton\n",
    "    time_interval = timedelta(minutes=20)\n",
    "    traveled_distance = 0\n",
    "    start_timestamp = datetime(2014, 7, 1)\n",
    "    current_timestamp = datetime(2014, 7, 1)\n",
    "\n",
    "    generated_od = pd.DataFrame(\n",
    "    columns=['licence', 'begin_time', 'end_time', 'load_hotspot', 'drop_hotspot', 'od_distance',\n",
    "             'traveled_from_charged', 'to_charge', 'cs_index', 'cs_name'])\n",
    "\n",
    "    for _, row in vehicle_rest.iterrows():\n",
    "        if row['begin_hour'] == -1:\n",
    "            row['begin_hour'] = 24\n",
    "            row['rest_length'] = 0\n",
    "        if current_timestamp > start_timestamp + timedelta(days=row['day'], hours=row['begin_hour']):\n",
    "            status = 'rest'\n",
    "        else:\n",
    "            status = 'occupied'\n",
    "            temp_distribution = departure_distributions[current_timestamp.hour]\n",
    "            load_hs = temp_distribution.sample(1, weights=temp_distribution).index[0]\n",
    "        while True:\n",
    "            if 'occupied' == status:\n",
    "                # Get time interval\n",
    "                window_index = (current_timestamp.hour * 3600 + current_timestamp.minute * 60) // time_interval.seconds\n",
    "                # 根据时间窗口取转移矩阵\n",
    "                p2d_transit = p2d[window_index]\n",
    "                p2d_transit_t = p2d_t[window_index]\n",
    "\n",
    "                # if pick-up hot spot in p2d matrix\n",
    "                if load_hs not in p2d_transit.index:\n",
    "                    # 寻找离当前出发hotspots最近的，有转移分布的hotspots作为替代出发hotspots\n",
    "                    # select load hot spots geodetic coordinates\n",
    "                    load_hotspots_loc = p_hs[['latitude', 'longitude']].values\n",
    "                    # select coordinates of hot spots that have drop distribution\n",
    "                    valid_load_hotspots_loc = load_hotspots_loc[p_hs.loc[p_hs['id'].isin(p2d_transit.index)].index]\n",
    "                    # original load hot spot geodetic coordinate\n",
    "                    load_offset = p_hs.loc[p_hs['id'] == load_hs].index[0]\n",
    "                    loc_a = p_hs.loc[[load_offset], ['latitude', 'longitude']].values\n",
    "                    # select nearest load hot spot\n",
    "                    nearest_offset = haversine_distances(np.radians(loc_a),\n",
    "                                                         np.radians(valid_load_hotspots_loc)).argmin()\n",
    "                    load_hs = p_hs.loc[p_hs['id'].isin(p2d_transit.index), 'id'].iloc[nearest_offset]\n",
    "                \n",
    "                transit_distribution = p2d_transit.loc[load_hs]\n",
    "                # select drop hotsopt by load hotspot and transit matrix\n",
    "                drop_hs = transit_distribution.sample(1, weights=transit_distribution).index[0]\n",
    "                \n",
    "                move_duration = p2d_transit_t.loc[load_hs, drop_hs]\n",
    "                move_distance = p2d_distance[load_hs, drop_hs]\n",
    "                \n",
    "                # Advance time and distance\n",
    "                current_timestamp += timedelta(seconds=move_duration)\n",
    "                traveled_distance += move_distance\n",
    "#                 print(vehicle_rest.name, current_timestamp, 'p2d', load_hs, drop_hs, 'travel', move_distance)\n",
    "                pre_status='occupied'\n",
    "                status='empty'\n",
    "            elif 'empty' == status:\n",
    "                # First predict charging behavior\n",
    "                if 'occupied' == pre_status:\n",
    "                    d_offset = d_hs.loc[d_hs['id'] == drop_hs].index[0]\n",
    "                    loc_d = d_hs.loc[[d_offset], ['latitude', 'longitude']].values\n",
    "                    AVG_EARTH_RADIUS = 6371.0088\n",
    "                    distances_to_cs = haversine_distances(np.radians(loc_d), np.radians(cs_location)) * AVG_EARTH_RADIUS\n",
    "                    time_of_day = current_timestamp.hour + current_timestamp.minute / 60 + current_timestamp.second / 3600\n",
    "\n",
    "                    whether_charge_features = [time_of_day, distances_to_cs.min(), distances_to_cs.max(),\n",
    "                                               distances_to_cs.mean(), np.median(distances_to_cs), traveled_distance]\n",
    "\n",
    "                    whether_charge_features_scaled = whether_charge_scaler.transform(np.reshape(whether_charge_features, \n",
    "                                                                                                (1, -1)))\n",
    "                    to_charge = wtc_model.predict(whether_charge_features_scaled)\n",
    "#                   columns=['licence', 'begin_time', 'end_time', 'load_hotspot', 'drop_hotspot', 'od_distance',\n",
    "#              'traveled_from_charged', 'to_charge', 'cs_index', 'cs_name'])\n",
    "                    if to_charge & (traveled_distance < 40):\n",
    "                        to_charge = np.array([0])\n",
    "                    elif ~to_charge & (traveled_distance > 180):\n",
    "                        to_charge = np.array([1])\n",
    "                    if to_charge:\n",
    "                        status = 'charging'\n",
    "                        continue\n",
    "                    else:\n",
    "                        # Generate data\n",
    "                        record = [vehicle_rest.name, current_timestamp - timedelta(seconds=move_duration),\n",
    "                                  current_timestamp, load_hs, drop_hs, move_distance, traveled_distance, \n",
    "                                  to_charge[0], None, None]\n",
    "                        generated_od.loc[generated_od.shape[0]] = record\n",
    "                if current_timestamp > start_timestamp + timedelta(days=row['day'], hours=row['begin_hour']):\n",
    "                    status = 'rest'\n",
    "                else:\n",
    "                    # Get time interval\n",
    "                    window_index = (current_timestamp.hour * 3600 + current_timestamp.minute * 60) \\\n",
    "                                   // time_interval.seconds\n",
    "                    # 根据时间窗口取转移矩阵\n",
    "                    d2p_transit = d2p[window_index]\n",
    "                    d2p_transit_t = d2p_t[window_index]\n",
    "\n",
    "                    # if drop-off hot spot in d2p matrix\n",
    "                    if (drop_hs not in d2p_transit.index) or ():\n",
    "                        # 寻找离当前drop hotspots最近的，有转移分布的hotspot作为替代drop hotspot\n",
    "                        # select drop-off hot spots geodetic coordinates\n",
    "                        drop_hotspots_loc = d_hs[['latitude', 'longitude']].values\n",
    "                        # select coordinates of hot spots that have load distribution\n",
    "                        valid_drop_hotspots_loc = drop_hotspots_loc[d_hs.loc[d_hs['id'].isin(d2p_transit.index)].index]\n",
    "                        # original drop hot spot geodetic coordinate\n",
    "                        d_offset = d_hs.loc[d_hs['id'] == drop_hs].index[0]\n",
    "                        loc_a = d_hs.loc[[d_offset], ['latitude', 'longitude']].values\n",
    "                        # select nearest drop hot spot\n",
    "                        nearest_offset = haversine_distances(np.radians(loc_a), \n",
    "                                                             np.radians(valid_drop_hotspots_loc)).argmin()\n",
    "                        drop_hs = d_hs.loc[d_hs['id'].isin(d2p_transit.index), 'id'].iloc[nearest_offset]\n",
    "                    transit_distribution = d2p_transit.loc[drop_hs]\n",
    "                    # select load hotsopt by drop hotspot and transit matrix\n",
    "\n",
    "                    load_hs = transit_distribution.sample(1, weights=transit_distribution).index[0]\n",
    "                    move_duration = d2p_transit_t.loc[drop_hs, load_hs]\n",
    "                    move_distance = d2p_distance[drop_hs, load_hs]\n",
    "                    # Advance time and distance\n",
    "                    current_timestamp += timedelta(seconds=move_duration)\n",
    "                    traveled_distance += move_distance\n",
    "#                         print(vehicle_rest.name, current_timestamp, 'd2p', drop_hs, load_hs, 'travel', move_distance)\n",
    "                    status='occupied'\n",
    "            elif 'charging' == status:\n",
    "                where_charge_features = pd.DataFrame(index=range(23))\n",
    "#                 [traveled_distance, distances_to_cs.min(), np.median(distances_to_cs), \n",
    "#                                                distances_to_cs.mean(), distances_to_cs.max(), time_of_day]\n",
    "                where_charge_features['max_dis'] = distances_to_cs.max()\n",
    "                where_charge_features['mean_dis'] = distances_to_cs.mean()\n",
    "                where_charge_features['mid_dis'] = np.median(distances_to_cs)\n",
    "                where_charge_features['min_dis'] = distances_to_cs.min()\n",
    "                where_charge_features['traveled_after_charged'] = traveled_distance\n",
    "                where_charge_features['distance'] = distances_to_cs.reshape((-1))\n",
    "                where_charge_features['weekday'] = 1 if current_timestamp.weekday() < 5 else 0\n",
    "                where_charge_features['time_of_day'] = time_of_day\n",
    "                where_charge_features['chg_points'] = df_cs['chg_points']\n",
    "                data = torch.from_numpy(where_charge_features.to_numpy()).to(device).float()\n",
    "                data = data.view(-1, 23, len(where_charge_features.columns))\n",
    "                output = model(data)\n",
    "                \n",
    "                output = softmax(output).view(-1).cpu().detach().numpy()\n",
    "                station_index = np.random.choice(len(output), 1, p=output).item()\n",
    "                \n",
    "#                 print('CS:', df_cs.loc[station_index, 'cs_name'], 'probability:', output[station_index])\n",
    "                # Generate data\n",
    "                record = [vehicle_rest.name, current_timestamp - timedelta(seconds=move_duration),\n",
    "                          current_timestamp, load_hs, drop_hs, move_distance, traveled_distance, to_charge[0],\n",
    "                          station_index, df_cs.loc[station_index, 'cs_name']]\n",
    "                generated_od.loc[generated_od.shape[0]] = record\n",
    "                current_timestamp += timedelta(hours=1.5)\n",
    "                pre_status = 'charging'\n",
    "                traveled_distance = 0\n",
    "                status = 'empty'\n",
    "            elif 'rest' == status:\n",
    "#                 print('rest', current_timestamp)\n",
    "                current_timestamp += timedelta(hours=row['rest_length'])\n",
    "                break\n",
    "    return generated_od\n",
    "\n",
    "generated_data = generated_rest.groupby('id').progress_apply(generation,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_data.to_csv('generated_data/generated_data_v4.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "et",
   "language": "python",
   "display_name": "Python (et)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}