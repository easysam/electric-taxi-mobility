{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import xgboost\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import utils.data_loader as data_loader\n",
    "import utils.display as display\n",
    "import utils.vector_haversine_distances as vec_hs_dis\n",
    "from scipy import stats\n",
    "from sklearn.metrics.pairwise import haversine_distances\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import sklearn\n",
    "from hotspot.hotpots_discovery_utils import generate_cube_index, cube_to_coordinate\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "display.configure_logging()\n",
    "display.configure_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def mape_vectorized_v2(a, b):\n",
    "    b = b.reshape(1, -1)\n",
    "    mask = a != 0\n",
    "    a = a[mask]\n",
    "    b = b[mask]\n",
    "    return (np.fabs(a - b)/a).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24-Jul-20 15:33:18 - Loading data/transaction_201407.csv\n"
     ]
    }
   ],
   "source": [
    "df_od = data_loader.load_od(scale='full', common=False)\n",
    "# 筛选出处于bbox中的points\n",
    "df_od['in_bbox'] = ((113.764635 < df_od['destination_log'])\n",
    "                     & (df_od['destination_log'] < 114.608972)\n",
    "                     & (22.454727 < df_od['destination_lat'])\n",
    "                     & (df_od['destination_lat'] < 22.842654)\n",
    "                     & (113.764635 < df_od['original_log'])\n",
    "                     & (df_od['original_log'] < 114.608972)\n",
    "                     & (22.454727 < df_od['original_lat'])\n",
    "                     & (df_od['original_lat'] < 22.842654))\n",
    "df_od = df_od.loc[df_od.in_bbox].reset_index(drop=True)\n",
    "df_od = generate_cube_index(df_od, m=100, n=200)\n",
    "\n",
    "demand = df_od.groupby(['original_cube', 'destination_cube']).size().reset_index()\n",
    "demand = demand.rename(columns={0: 'demand'})\n",
    "\n",
    "demand = demand.loc[demand['demand'] > 10].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24-Jul-20 15:33:48 - Loading data/transaction_common_201407.csv\n"
     ]
    }
   ],
   "source": [
    "df_et_od = data_loader.load_od(scale='full', common=True)\n",
    "# 筛选出处于bbox中的points\n",
    "df_et_od['in_bbox'] = ((113.764635 < df_et_od['destination_log'])\n",
    "                     & (df_et_od['destination_log'] < 114.608972)\n",
    "                     & (22.454727 < df_et_od['destination_lat'])\n",
    "                     & (df_et_od['destination_lat'] < 22.842654)\n",
    "                     & (113.764635 < df_et_od['original_log'])\n",
    "                     & (df_et_od['original_log'] < 114.608972)\n",
    "                     & (22.454727 < df_et_od['original_lat'])\n",
    "                     & (df_et_od['original_lat'] < 22.842654))\n",
    "df_et_od = df_et_od.loc[df_et_od.in_bbox].reset_index(drop=True)\n",
    "df_et_od = generate_cube_index(df_et_od, m=100, n=200)\n",
    "\n",
    "et_demand = df_et_od.groupby(['original_cube', 'destination_cube']).size().reset_index()\n",
    "et_demand = et_demand.rename(columns={0: 'demand'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_demands = pd.merge(demand, et_demand, how='left', on=['original_cube', 'destination_cube'], suffixes=('_all', '_et'))\n",
    "df_demands = df_demands.fillna(0)\n",
    "df_demands['rate'] = df_demands['demand_et'] / df_demands['demand_all']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_od['duration'] = (df_od['end_time'] - df_od['begin_time']).dt.total_seconds()\n",
    "df_od = df_od[['original_cube', 'destination_cube', 'original_log', 'original_lat', 'destination_log',\n",
    "               'destination_lat', 'duration']].groupby(['original_cube', 'destination_cube']).mean()\n",
    "df_od.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24-Jul-20 15:33:50 - Loadingdata/cs/ChargeLocation201407\n"
     ]
    }
   ],
   "source": [
    "df_od_pairs = pd.merge(df_demands[['original_cube', 'destination_cube']],\n",
    "                       df_od[['original_cube', 'destination_cube', 'original_log', 'original_lat', 'destination_log',\n",
    "                              'destination_lat', 'duration']],\n",
    "                       left_on=['original_cube', 'destination_cube'],\n",
    "                       right_on=['original_cube', 'destination_cube'])\n",
    "\n",
    "# df_od_pairs = df_od_pairs.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "df_cs, date = data_loader.load_cs(scale='part', date=datetime.datetime(2014, 7, 1))\n",
    "df_cs = df_cs.loc[~df_cs['cs_name'].isin(['LJDL', 'E04', 'BN0002', 'F11', 'S1', 'S2', 'F12', 'F13', 'F15'])]\n",
    "df_cs.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# select drop location and CS location as two array\n",
    "original_locations = df_od_pairs[['original_lat', 'original_log']].to_numpy()\n",
    "destination_locations = df_od_pairs[['destination_lat', 'destination_log']].to_numpy()\n",
    "cs_location = df_cs[['Latitude', 'Longitude']].to_numpy()\n",
    "\n",
    "# earth radius(km)\n",
    "AVG_EARTH_RADIUS = 6371.0088\n",
    "\n",
    "# calculate distance between original/destination location and CS location\n",
    "original_distances_to_cs = haversine_distances(np.radians(original_locations), np.radians(cs_location)) \\\n",
    "                           * AVG_EARTH_RADIUS\n",
    "destination_distances_to_cs = haversine_distances(np.radians(destination_locations), np.radians(cs_location)) \\\n",
    "                              * AVG_EARTH_RADIUS\n",
    "# calculate distance between od locations\n",
    "od_dis = vec_hs_dis.haversine_np(df_od_pairs['original_log'], df_od_pairs['original_lat'],\n",
    "                                 df_od_pairs['destination_log'], df_od_pairs['destination_lat'])\n",
    "\n",
    "df_original_distances_to_cs = pd.DataFrame(original_distances_to_cs)\n",
    "df_destination_distances_to_cs = pd.DataFrame(destination_distances_to_cs)\n",
    "df_od_dis = pd.DataFrame(od_dis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106788 sample\n",
      "3 nearest cs as feature:\n",
      "train data shape: (4003, 14)\n",
      "test data shape: (1001, 14)\n",
      "mae: 0.026461035292838 mse: 0.0020419696121095955 rmse: 0.04518815787470867\n",
      "mape: 0.3501005397370062\n",
      "R2: 0.5141357348305923\n",
      "[0.12280702 0.04511278 0.03831418 0.03508772 0.05108055 0.14851485]\n",
      "[0.09802815 0.05021524 0.05168721 0.10367793 0.05502495 0.12419114]\n",
      "[0.04051173 0.12195122 0.04009434 0.10526316 0.06593407 0.05940594]\n",
      "[0.05017522 0.06613648 0.05212858 0.10769045 0.08858252 0.07811704]\n"
     ]
    }
   ],
   "source": [
    "def evaluate(n=10):\n",
    "    original_capacity = np.repeat(df_cs['chg_points'].values.reshape(1, -1), df_od_pairs.shape[0], axis=0)\n",
    "\n",
    "    a = df_original_distances_to_cs.values\n",
    "    a.sort(axis=1)\n",
    "    a = pd.DataFrame(a, df_original_distances_to_cs.index, df_original_distances_to_cs.columns)\n",
    "    a = a.iloc[:, :n]\n",
    "    o_dissorted_capacity = np.take_along_axis(original_capacity, df_original_distances_to_cs.values.argsort(axis=1),\n",
    "                                              axis=1)\n",
    "    o_dissorted_capacity = pd.DataFrame(o_dissorted_capacity)\n",
    "    o_dissorted_capacity = o_dissorted_capacity.iloc[:, :n]\n",
    "\n",
    "    b = df_destination_distances_to_cs.values\n",
    "    b.sort(axis=1)\n",
    "    b = pd.DataFrame(b, df_destination_distances_to_cs.index, df_destination_distances_to_cs.columns)\n",
    "    b = b.iloc[:, :n]\n",
    "    d_dissorted_capacity = np.take_along_axis(original_capacity, df_destination_distances_to_cs.values.argsort(axis=1),\n",
    "                                              axis=1)\n",
    "    d_dissorted_capacity = pd.DataFrame(d_dissorted_capacity)\n",
    "    d_dissorted_capacity = d_dissorted_capacity.iloc[:, :n]\n",
    "\n",
    "    # train_x, val_x, train_y, val_y = train_test_split(\n",
    "    #     pd.concat([df_od_pairs['duration'], od_dis, a, o_dissorted_capacity, b, d_dissorted_capacity],axis=1).values,\n",
    "    #     df_demands['rate'].values, test_size=0.2)\n",
    "    data_set = pd.concat([df_od_pairs['duration'], od_dis, a, o_dissorted_capacity, b, d_dissorted_capacity,\n",
    "               df_demands['demand_et'], df_demands['rate']], axis=1)\n",
    "    data_set = data_set.loc[data_set['demand_et'] > 5]\n",
    "    train_x, val_x, train_y, val_y = train_test_split(data_set.iloc[:, :-2].values,\n",
    "                                                      data_set.iloc[:, -1].values, test_size=0.2)\n",
    "    print('train data shape:', train_x.shape)\n",
    "    print('test data shape:', val_x.shape)\n",
    "    scaler = sklearn.preprocessing.StandardScaler()\n",
    "    train_x = scaler.fit_transform(train_x)\n",
    "    val_x = scaler.transform(val_x)\n",
    "\n",
    "    gbm = xgboost.XGBRegressor(verbosity=0, n_estimators=100, validate_parameters=2, \n",
    "                               learning_rate=0.05, min_child_weight=5, max_depth=8)\n",
    "\n",
    "    gbm.fit(train_x, train_y)\n",
    "    predict_y = gbm.predict(val_x)\n",
    "\n",
    "    print('mae:', mean_absolute_error(val_y, predict_y),\n",
    "          'mse:', mean_squared_error(val_y, predict_y),\n",
    "          'rmse:', mean_squared_error(val_y, predict_y, squared=False))\n",
    "    print('mape:', mape_vectorized_v2(val_y.reshape(1, -1), predict_y))\n",
    "    print('R2:', gbm.score(val_x, val_y))\n",
    "    print(val_y[30:36], )\n",
    "    print(predict_y[30:36])\n",
    "    print(val_y[50:56], )\n",
    "    print(predict_y[50:56])\n",
    "\n",
    "print(df_od_pairs.shape[0], 'sample')\n",
    "for i in range(3, 4):\n",
    "    print(i, 'nearest cs as feature:')\n",
    "    evaluate(n=i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "outputs": [
    {
     "data": {
      "text/plain": "               index  original_cube  destination_cube     demand_all      demand_et           rate\ncount  106788.000000  106788.000000      106788.00000  106788.000000  106788.000000  106788.000000\nmean   579180.341508   13816.367082       13778.56040      36.811393       1.383835       0.037035\nstd    264718.064414    2694.106499        2705.44901      52.576251       2.785713       0.049223\nmin      1708.000000    2830.000000        3229.00000      11.000000       0.000000       0.000000\n25%    373768.750000   12483.000000       12466.00000      14.000000       0.000000       0.000000\n50%    622343.500000   14684.000000       14666.00000      21.000000       1.000000       0.017857\n75%    802127.250000   15656.000000       15651.00000      38.000000       2.000000       0.062500\nmax    994057.000000   18634.000000       19031.00000    3672.000000     129.000000       0.823529",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>original_cube</th>\n      <th>destination_cube</th>\n      <th>demand_all</th>\n      <th>demand_et</th>\n      <th>rate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>106788.000000</td>\n      <td>106788.000000</td>\n      <td>106788.00000</td>\n      <td>106788.000000</td>\n      <td>106788.000000</td>\n      <td>106788.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>579180.341508</td>\n      <td>13816.367082</td>\n      <td>13778.56040</td>\n      <td>36.811393</td>\n      <td>1.383835</td>\n      <td>0.037035</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>264718.064414</td>\n      <td>2694.106499</td>\n      <td>2705.44901</td>\n      <td>52.576251</td>\n      <td>2.785713</td>\n      <td>0.049223</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1708.000000</td>\n      <td>2830.000000</td>\n      <td>3229.00000</td>\n      <td>11.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>373768.750000</td>\n      <td>12483.000000</td>\n      <td>12466.00000</td>\n      <td>14.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>622343.500000</td>\n      <td>14684.000000</td>\n      <td>14666.00000</td>\n      <td>21.000000</td>\n      <td>1.000000</td>\n      <td>0.017857</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>802127.250000</td>\n      <td>15656.000000</td>\n      <td>15651.00000</td>\n      <td>38.000000</td>\n      <td>2.000000</td>\n      <td>0.062500</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>994057.000000</td>\n      <td>18634.000000</td>\n      <td>19031.00000</td>\n      <td>3672.000000</td>\n      <td>129.000000</td>\n      <td>0.823529</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_demands.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106788 sample\n",
      "1 nearest cs as feature:\n",
      "(85430, 6) (85430,)\n",
      "(21358, 6) (21358,)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-15-a0896c0a7b1d>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     65\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mi\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m10\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     66\u001B[0m     \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mi\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'nearest cs as feature:'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 67\u001B[1;33m     \u001B[0mevaluate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mn\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mi\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m<ipython-input-15-a0896c0a7b1d>\u001B[0m in \u001B[0;36mevaluate\u001B[1;34m(n)\u001B[0m\n\u001B[0;32m     46\u001B[0m     \u001B[0mval_x\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mscaler\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtransform\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mval_x\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     47\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 48\u001B[1;33m     \u001B[0mgs\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtrain_x\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtrain_y\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     49\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     50\u001B[0m     \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mgs\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbest_params_\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\et\\lib\\site-packages\\sklearn\\utils\\validation.py\u001B[0m in \u001B[0;36minner_f\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     71\u001B[0m                           FutureWarning)\n\u001B[0;32m     72\u001B[0m         \u001B[0mkwargs\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mupdate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m{\u001B[0m\u001B[0mk\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0marg\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mk\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0marg\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mzip\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msig\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mparameters\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0margs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m}\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 73\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mf\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     74\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[0minner_f\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     75\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\et\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001B[0m in \u001B[0;36mfit\u001B[1;34m(self, X, y, groups, **fit_params)\u001B[0m\n\u001B[0;32m    734\u001B[0m                 \u001B[1;32mreturn\u001B[0m \u001B[0mresults\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    735\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 736\u001B[1;33m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_run_search\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mevaluate_candidates\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    737\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    738\u001B[0m         \u001B[1;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\et\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001B[0m in \u001B[0;36m_run_search\u001B[1;34m(self, evaluate_candidates)\u001B[0m\n\u001B[0;32m   1186\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m_run_search\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mevaluate_candidates\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1187\u001B[0m         \u001B[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1188\u001B[1;33m         \u001B[0mevaluate_candidates\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mParameterGrid\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mparam_grid\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1189\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1190\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\et\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001B[0m in \u001B[0;36mevaluate_candidates\u001B[1;34m(candidate_params)\u001B[0m\n\u001B[0;32m    713\u001B[0m                                \u001B[1;32mfor\u001B[0m \u001B[0mparameters\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mtrain\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtest\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    714\u001B[0m                                in product(candidate_params,\n\u001B[1;32m--> 715\u001B[1;33m                                           cv.split(X, y, groups)))\n\u001B[0m\u001B[0;32m    716\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    717\u001B[0m                 \u001B[1;32mif\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mout\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m<\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\et\\lib\\site-packages\\joblib\\parallel.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, iterable)\u001B[0m\n\u001B[0;32m   1030\u001B[0m                 \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_iterating\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_original_iterator\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1031\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1032\u001B[1;33m             \u001B[1;32mwhile\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdispatch_one_batch\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0miterator\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1033\u001B[0m                 \u001B[1;32mpass\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1034\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\et\\lib\\site-packages\\joblib\\parallel.py\u001B[0m in \u001B[0;36mdispatch_one_batch\u001B[1;34m(self, iterator)\u001B[0m\n\u001B[0;32m    845\u001B[0m                 \u001B[1;32mreturn\u001B[0m \u001B[1;32mFalse\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    846\u001B[0m             \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 847\u001B[1;33m                 \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_dispatch\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtasks\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    848\u001B[0m                 \u001B[1;32mreturn\u001B[0m \u001B[1;32mTrue\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    849\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\et\\lib\\site-packages\\joblib\\parallel.py\u001B[0m in \u001B[0;36m_dispatch\u001B[1;34m(self, batch)\u001B[0m\n\u001B[0;32m    763\u001B[0m         \u001B[1;32mwith\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_lock\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    764\u001B[0m             \u001B[0mjob_idx\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_jobs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 765\u001B[1;33m             \u001B[0mjob\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_backend\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mapply_async\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mbatch\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcallback\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mcb\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    766\u001B[0m             \u001B[1;31m# A job can complete so quickly than its callback is\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    767\u001B[0m             \u001B[1;31m# called before we get here, causing self._jobs to\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\et\\lib\\site-packages\\joblib\\_parallel_backends.py\u001B[0m in \u001B[0;36mapply_async\u001B[1;34m(self, func, callback)\u001B[0m\n\u001B[0;32m    206\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mapply_async\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfunc\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcallback\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mNone\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    207\u001B[0m         \u001B[1;34m\"\"\"Schedule a func to be run\"\"\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 208\u001B[1;33m         \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mImmediateResult\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfunc\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    209\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mcallback\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    210\u001B[0m             \u001B[0mcallback\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mresult\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\et\\lib\\site-packages\\joblib\\_parallel_backends.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, batch)\u001B[0m\n\u001B[0;32m    570\u001B[0m         \u001B[1;31m# Don't delay the application, to avoid keeping the input\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    571\u001B[0m         \u001B[1;31m# arguments in memory\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 572\u001B[1;33m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mresults\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mbatch\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    573\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    574\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mget\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\et\\lib\\site-packages\\joblib\\parallel.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    251\u001B[0m         \u001B[1;32mwith\u001B[0m \u001B[0mparallel_backend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_backend\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mn_jobs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_n_jobs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    252\u001B[0m             return [func(*args, **kwargs)\n\u001B[1;32m--> 253\u001B[1;33m                     for func, args, kwargs in self.items]\n\u001B[0m\u001B[0;32m    254\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    255\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m__reduce__\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\et\\lib\\site-packages\\joblib\\parallel.py\u001B[0m in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m    251\u001B[0m         \u001B[1;32mwith\u001B[0m \u001B[0mparallel_backend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_backend\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mn_jobs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_n_jobs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    252\u001B[0m             return [func(*args, **kwargs)\n\u001B[1;32m--> 253\u001B[1;33m                     for func, args, kwargs in self.items]\n\u001B[0m\u001B[0;32m    254\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    255\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m__reduce__\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\et\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001B[0m in \u001B[0;36m_fit_and_score\u001B[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001B[0m\n\u001B[0;32m    529\u001B[0m             \u001B[0mestimator\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX_train\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mfit_params\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    530\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 531\u001B[1;33m             \u001B[0mestimator\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX_train\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_train\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mfit_params\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    532\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    533\u001B[0m     \u001B[1;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\et\\lib\\site-packages\\xgboost\\sklearn.py\u001B[0m in \u001B[0;36mfit\u001B[1;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, callbacks)\u001B[0m\n\u001B[0;32m    542\u001B[0m                               \u001B[0mevals_result\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mevals_result\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mobj\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mobj\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfeval\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mfeval\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    543\u001B[0m                               \u001B[0mverbose_eval\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mverbose\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mxgb_model\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mxgb_model\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 544\u001B[1;33m                               callbacks=callbacks)\n\u001B[0m\u001B[0;32m    545\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    546\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mevals_result\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\et\\lib\\site-packages\\xgboost\\training.py\u001B[0m in \u001B[0;36mtrain\u001B[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks)\u001B[0m\n\u001B[0;32m    210\u001B[0m                            \u001B[0mevals\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mevals\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    211\u001B[0m                            \u001B[0mobj\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mobj\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfeval\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mfeval\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 212\u001B[1;33m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001B[0m\u001B[0;32m    213\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    214\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\et\\lib\\site-packages\\xgboost\\training.py\u001B[0m in \u001B[0;36m_train_internal\u001B[1;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001B[0m\n\u001B[0;32m     73\u001B[0m         \u001B[1;31m# Skip the first update if it is a recovery step.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     74\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mversion\u001B[0m \u001B[1;33m%\u001B[0m \u001B[1;36m2\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 75\u001B[1;33m             \u001B[0mbst\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mupdate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdtrain\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mi\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mobj\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     76\u001B[0m             \u001B[0mbst\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msave_rabit_checkpoint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     77\u001B[0m             \u001B[0mversion\u001B[0m \u001B[1;33m+=\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\et\\lib\\site-packages\\xgboost\\core.py\u001B[0m in \u001B[0;36mupdate\u001B[1;34m(self, dtrain, iteration, fobj)\u001B[0m\n\u001B[0;32m   1367\u001B[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n\u001B[0;32m   1368\u001B[0m                                                     \u001B[0mctypes\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mc_int\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0miteration\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1369\u001B[1;33m                                                     dtrain.handle))\n\u001B[0m\u001B[0;32m   1370\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1371\u001B[0m             \u001B[0mpred\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpredict\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdtrain\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0moutput_margin\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mTrue\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtraining\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mTrue\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "exit(0)\n",
    "# This cell is used to search parameters.\n",
    "def evaluate(n=10):\n",
    "    original_capacity = np.repeat(df_cs['chg_points'].values.reshape(1, -1), df_od_pairs.shape[0], axis=0)\n",
    "\n",
    "    a = df_original_distances_to_cs.values\n",
    "    a.sort(axis=1)\n",
    "    a = pd.DataFrame(a, df_original_distances_to_cs.index, df_original_distances_to_cs.columns)\n",
    "    a = a.iloc[:, :n]\n",
    "    o_dissorted_capacity = np.take_along_axis(original_capacity, df_original_distances_to_cs.values.argsort(axis=1),\n",
    "                                              axis=1)\n",
    "    o_dissorted_capacity = pd.DataFrame(o_dissorted_capacity)\n",
    "    o_dissorted_capacity = o_dissorted_capacity.iloc[:, :n]\n",
    "\n",
    "    b = df_destination_distances_to_cs.values\n",
    "    b.sort(axis=1)\n",
    "    b = pd.DataFrame(b, df_destination_distances_to_cs.index, df_destination_distances_to_cs.columns)\n",
    "    b = b.iloc[:, :n]\n",
    "    d_dissorted_capacity = np.take_along_axis(original_capacity, df_destination_distances_to_cs.values.argsort(axis=1),\n",
    "                                              axis=1)\n",
    "    d_dissorted_capacity = pd.DataFrame(d_dissorted_capacity)\n",
    "    d_dissorted_capacity = d_dissorted_capacity.iloc[:, :n]\n",
    "\n",
    "    gbm = xgboost.XGBRegressor(verbosity=0, validate_parameters=2,)\n",
    "\n",
    "    param_grid = {\n",
    "        'n_estimators': [50, 100],\n",
    "        'scale_pos_weight': [1, 3],\n",
    "        'max_depth': [5, 10],\n",
    "        'learning_rate': [0.05, 0.1],\n",
    "        'min_child_weight': [1, 3],\n",
    "        'gamma': [0, 5,],\n",
    "        'max_delta_step': [0, 3],\n",
    "        'subsample': [0.7, 1],\n",
    "        'colsample_bytree': [0.7, 1]\n",
    "    }\n",
    "    gs = GridSearchCV(gbm, param_grid=param_grid, cv=5)\n",
    "\n",
    "    train_x, val_x, train_y, val_y = train_test_split(\n",
    "        pd.concat([df_od_pairs['duration'], od_dis, a, o_dissorted_capacity, b, d_dissorted_capacity],axis=1).values,\n",
    "        df_demands['rate'].values, test_size=0.2)\n",
    "    print(train_x.shape, train_y.shape)\n",
    "    print(val_x.shape, val_y.shape)\n",
    "    scaler = sklearn.preprocessing.StandardScaler()\n",
    "    train_x = scaler.fit_transform(train_x)\n",
    "    val_x = scaler.transform(val_x)\n",
    "\n",
    "    gs.fit(train_x, train_y)\n",
    "\n",
    "    print(gs.best_params_)\n",
    "    print(gs.best_score_)\n",
    "    print(gs.best_estimator_)\n",
    "    print(gs.best_index_)\n",
    "\n",
    "    gs.best_estimator_.fit(train_x, train_y)\n",
    "    predict_y = gs.best_estimator_.predict(val_x)\n",
    "\n",
    "    print('mape:', mape_vectorized_v2(val_y.reshape(-1), predict_y))\n",
    "    print('xgb score (rmse in xgb doc):', gs.best_estimator_.score(val_x, val_y))\n",
    "    print('gs score (neg rmse):', gs.score(val_x, val_y))\n",
    "    print('sample_gt:', val_y[10:15])\n",
    "    print('sample_pred:', predict_y[10:15])\n",
    "\n",
    "print(df_od_pairs.shape[0], 'sample')\n",
    "for i in range(1, 10):\n",
    "    print(i, 'nearest cs as feature:')\n",
    "    evaluate(n=i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "et",
   "language": "python",
   "display_name": "Python (et)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}